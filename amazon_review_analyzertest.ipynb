{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd656b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: selenium in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from wordcloud) (9.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chaithanya ganesh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install selenium\n",
    "!pip install nltk\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter up to 10 Amazon product URLs (press Enter after each URL, type 'done' when finished):\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Initialize Chrome WebDriver with headless option\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Initialize VADER Sentiment Analyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to scrape Amazon reviews\n",
    "def scrape_amazon_reviews(product_urls):\n",
    "    reviews = []\n",
    "    for url in product_urls:\n",
    "        driver.get(url)\n",
    "        for _ in range(5):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        review_elements = soup.find_all('span', {'data-hook': 'review-body'})\n",
    "        for review in review_elements:\n",
    "            reviews.append(review.get_text(strip=True))\n",
    "    return reviews\n",
    "\n",
    "# Function to classify sentiment using VADER\n",
    "def classify_sentiment(comment):\n",
    "    scores = vader.polarity_scores(comment)\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Function to save comments with sentiments to TSV file\n",
    "def save_to_tsv_file(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(\"Sentiment\\tReview\\n\")\n",
    "        for comment in data:\n",
    "            sentiment = classify_sentiment(comment)\n",
    "            file.write(\"%s\\t%s\\n\" % (sentiment, comment))\n",
    "\n",
    "# Function to get input of Amazon product URLs\n",
    "def get_amazon_product_urls():\n",
    "    urls = []\n",
    "    print(\"Enter up to 10 Amazon product URLs (press Enter after each URL, type 'done' when finished):\")\n",
    "    for i in range(10):\n",
    "        url = input(f\"Enter URL {i+1}: \")\n",
    "        if url.strip().lower() == 'done':\n",
    "            break\n",
    "        urls.append(url.strip())\n",
    "    return urls\n",
    "\n",
    "# Example usage\n",
    "amazon_product_urls = get_amazon_product_urls()\n",
    "amazon_reviews = scrape_amazon_reviews(amazon_product_urls)\n",
    "save_to_tsv_file(amazon_reviews, 'amazon_reviews.tsv')\n",
    "\n",
    "# Load reviews from TSV file into DataFrame\n",
    "df = pd.read_csv('amazon_reviews.tsv', sep='\\t')\n",
    "\n",
    "# Drop NaN values and remove empty reviews\n",
    "df.dropna(inplace=True)\n",
    "empty_objects = []\n",
    "for index, label, review in df.itertuples():\n",
    "    if type(review)==str:\n",
    "        if review.isspace():\n",
    "            empty_objects.append(i)\n",
    "df.drop(empty_objects, inplace=True)\n",
    "\n",
    "# Calculate sentiment scores for each review\n",
    "df['scores'] = df['Review'].apply(lambda review: vader.polarity_scores(review))\n",
    "df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "# Calculate average compound score\n",
    "average_compound = df['compound'].mean()\n",
    "\n",
    "# Count positive, negative, and neutral reviews\n",
    "compound_greater_than_zero = df[df['compound'] > 0]['compound']\n",
    "compound_less_than_zero = df[df['compound'] < 0]['compound']\n",
    "compound_equal_to_zero = df[df['compound'] == 0]['compound']\n",
    "\n",
    "# Print statistics\n",
    "print(\"Average sentiment score:\", average_compound)\n",
    "print(\"Total number of positive reviews:\", compound_greater_than_zero.count())\n",
    "print(\"Total number of negative reviews:\", compound_less_than_zero.count())\n",
    "print(\"Total number of neutral reviews:\", compound_equal_to_zero.count())\n",
    "\n",
    "# Generate WordCloud from all reviews\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def filter_words(words):\n",
    "    tagged_words = pos_tag(words)\n",
    "    filtered_words = [word for word, tag in tagged_words if tag.startswith('N') or tag.startswith('J') or tag.startswith('V')]\n",
    "    return filtered_words\n",
    "\n",
    "df['filtered_comment'] = df['Review'].apply(lambda review: filter_words(word_tokenize(review)))\n",
    "all_words = [word for words in df['filtered_comment'] for word in words]\n",
    "all_text = ' '.join(all_words)\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of All Reviews')\n",
    "plt.show()\n",
    "\n",
    "# Generate WordCloud from negative reviews\n",
    "filtered_negative_comments = negative_comments.apply(lambda review: filter_words(word_tokenize(review)))\n",
    "all_negative_words = [word for words in filtered_negative_comments for word in words]\n",
    "all_negative_text = ' '.join(all_negative_words)\n",
    "\n",
    "wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(all_negative_text)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud_negative, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Negative Reviews')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691c32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
